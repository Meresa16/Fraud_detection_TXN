{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "af667f17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 03_ml_modeling.ipynb\n",
    "\n",
    "# import sys\n",
    "# sys.path.append(\"../src\")\n",
    "# from modeling import split_X_y, split_train_test, scale_features, train_simple_model, evaluate_model\n",
    "# import pandas as pd\n",
    "\n",
    "# # --- Load Processed CSV ---\n",
    "# df = pd.read_csv(\"../data/processed/bank_transactions_features.csv\")\n",
    "\n",
    "# # --- Split features / target ---\n",
    "# X, y = split_X_y(df, \"Is_Fraud\")\n",
    "\n",
    "# # --- Train/Test Split ---\n",
    "# X_train, X_test, y_train, y_test = split_train_test(X, y, stratify=y)\n",
    "\n",
    "# # --- Scale numeric features ---\n",
    "# X_train_s, X_test_s = scale_features(X_train, X_test)\n",
    "\n",
    "# # --- Train Logistic Regression ---\n",
    "# clf = train_simple_model(X_train_s.fillna(0), y_train, problem=\"classification\", model_name=\"logistic\")\n",
    "\n",
    "# # --- Evaluate ---\n",
    "# metrics = evaluate_model(clf, X_test_s.fillna(0), y_test)\n",
    "# print(metrics)\n",
    "\n",
    "# # --- Save Model ---\n",
    "# import joblib\n",
    "# joblib.dump(clf, \"../model/logistic_model.pkl\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7a1afb7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import sys\n",
    "# sys.path.append(\"../src/\")\n",
    "\n",
    "# import pandas as pd\n",
    "# import joblib\n",
    "# from modeling import split_X_y, split_train_test, scale_features, train_simple_model, evaluate_model\n",
    "\n",
    "# # --- Load processed CSV (already one-hot encoded) ---\n",
    "# FEATURES_PATH = \"../data/processed/bank_transactions_features.csv\"\n",
    "# df = pd.read_csv(FEATURES_PATH)\n",
    "\n",
    "# # --- Split X / y ---\n",
    "# X = df.drop(columns=[\"Is_Fraud\"])\n",
    "# y = df[\"Is_Fraud\"]\n",
    "\n",
    "# # --- Save column order BEFORE training (for dashboard consistency) ---\n",
    "# columns_used = X.columns.tolist()\n",
    "# joblib.dump(columns_used, \"../model/columns_used.pkl\")\n",
    "\n",
    "# # --- Train/Test split ---\n",
    "# X_train, X_test, y_train, y_test = split_train_test(X, y, stratify=y)\n",
    "\n",
    "# # --- Optional: Scale numeric features ---\n",
    "# X_train_s, X_test_s = scale_features(X_train.fillna(0), X_test.fillna(0))\n",
    "\n",
    "# # --- Train model (Random Forest with class balancing) ---\n",
    "# clf = train_simple_model(\n",
    "#     X_train_s,\n",
    "#     y_train,\n",
    "#     problem=\"classification\",\n",
    "#     model_name=\"random_forest\",\n",
    "#     random_state=42,\n",
    "#     n_estimators=200,\n",
    "#     max_depth=10,\n",
    "#     class_weight=\"balanced\"\n",
    "# )\n",
    "\n",
    "# # --- Evaluate ---\n",
    "# metrics = evaluate_model(clf, X_test_s, y_test)\n",
    "# print(\"Model Evaluation Metrics:\", metrics)\n",
    "\n",
    "# # --- Save trained model ---\n",
    "# MODEL_PATH = \"../model/rf_model.pkl\"\n",
    "# joblib.dump(clf, MODEL_PATH)\n",
    "# print(f\"Random Forest model saved at: {MODEL_PATH}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c7fefdb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import sys\n",
    "# sys.path.append(\"../src/\")\n",
    "\n",
    "# import pandas as pd\n",
    "# import joblib\n",
    "# from modeling import split_X_y, split_train_test, scale_features, train_simple_model, evaluate_model\n",
    "# from imblearn.ensemble import BalancedRandomForestClassifier\n",
    "# from sklearn.metrics import classification_report\n",
    "\n",
    "# # --- Load processed CSV (already one-hot encoded) ---\n",
    "# FEATURES_PATH = \"../data/processed/bank_transactions_features.csv\"\n",
    "# df = pd.read_csv(FEATURES_PATH)\n",
    "\n",
    "# # --- Split X / y ---\n",
    "# X = df.drop(columns=[\"Is_Fraud\"])\n",
    "# y = df[\"Is_Fraud\"]\n",
    "\n",
    "# # --- Save column order BEFORE training (for dashboard consistency) ---\n",
    "# columns_used = X.columns.tolist()\n",
    "# joblib.dump(columns_used, \"../model/columns_used.pkl\")\n",
    "\n",
    "# # --- Train/Test split ---\n",
    "# X_train, X_test, y_train, y_test = split_train_test(X, y, stratify=y)\n",
    "\n",
    "# # --- Optional: Scale numeric features ---\n",
    "# X_train_s, X_test_s = scale_features(X_train.fillna(0), X_test.fillna(0))\n",
    "\n",
    "# # --- Train model for imbalanced data ---\n",
    "# clf = BalancedRandomForestClassifier(\n",
    "#     n_estimators=300,\n",
    "#     max_depth=10,\n",
    "#     random_state=42,\n",
    "#     replacement=True  # allows sampling with replacement\n",
    "# )\n",
    "# clf.fit(X_train_s, y_train)\n",
    "\n",
    "# # --- Evaluate ---\n",
    "# y_pred = clf.predict(X_test_s)\n",
    "# print(\"Classification Report:\\n\", classification_report(y_test, y_pred, digits=4))\n",
    "\n",
    "# # ROC AUC for imbalanced data\n",
    "# if hasattr(clf, \"predict_proba\"):\n",
    "#     y_prob = clf.predict_proba(X_test_s)[:, 1]\n",
    "#     from sklearn.metrics import roc_auc_score\n",
    "#     auc = roc_auc_score(y_test, y_prob)\n",
    "#     print(f\"ROC AUC: {auc:.4f}\")\n",
    "\n",
    "# # --- Save trained model ---\n",
    "# MODEL_PATH = \"../model/rf_model_imbalanced.pkl\"\n",
    "# joblib.dump(clf, MODEL_PATH)\n",
    "# print(f\"Balanced Random Forest model saved at: {MODEL_PATH}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5d17cff4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import sys\n",
    "# import os\n",
    "# import pandas as pd\n",
    "# import joblib\n",
    "# import numpy as np\n",
    "\n",
    "# # Add src to path\n",
    "# sys.path.append(\"../src/\")\n",
    "\n",
    "# from modeling import split_X_y, split_train_test, scale_features, train_simple_model, evaluate_model\n",
    "# from imblearn.ensemble import BalancedRandomForestClassifier\n",
    "# from sklearn.metrics import classification_report, roc_auc_score, confusion_matrix\n",
    "\n",
    "# # =====================================================\n",
    "# # 1. SETUP & LOAD\n",
    "# # =====================================================\n",
    "# # Ensure model directory exists\n",
    "# os.makedirs(\"../model\", exist_ok=True)\n",
    "\n",
    "# FEATURES_PATH = \"../data/processed/bank_transactions_features.csv\"\n",
    "# print(f\"Loading data from {FEATURES_PATH}...\")\n",
    "# df = pd.read_csv(FEATURES_PATH)\n",
    "\n",
    "# # =====================================================\n",
    "# # 2. SPLITTING\n",
    "# # =====================================================\n",
    "# # Use helper to split X and y\n",
    "# X, y = split_X_y(df, target=\"Is_Fraud\")\n",
    "\n",
    "# # --- SAVE COLUMN METADATA ---\n",
    "# # Crucial: Save the column names so the dashboard knows the exact expected input order\n",
    "# cols_path = \"../model/columns_used.pkl\"\n",
    "# joblib.dump(X.columns.tolist(), cols_path)\n",
    "# print(f\"Saved feature column list to {cols_path}\")\n",
    "\n",
    "# # Split Train/Test\n",
    "# X_train, X_test, y_train, y_test = split_train_test(X, y, stratify=y)\n",
    "\n",
    "# # =====================================================\n",
    "# # 3. PREPROCESSING (Minimal for Trees)\n",
    "# # =====================================================\n",
    "# # Note: Tree-based models (Random Forest) do not require scaling.\n",
    "# # We skip StandardScaling to simplify the inference pipeline.\n",
    "# # We only ensure no NaNs exist (though clean_missing should have handled this).\n",
    "\n",
    "# X_train = X_train.fillna(0)\n",
    "# X_test = X_test.fillna(0)\n",
    "\n",
    "# # =====================================================\n",
    "# # 4. TRAINING\n",
    "# # =====================================================\n",
    "# print(\"Training BalancedRandomForestClassifier...\")\n",
    "# # BalancedRandomForest undersamples the majority class inside each bootstrap sample\n",
    "# clf = BalancedRandomForestClassifier(\n",
    "#     n_estimators=300,\n",
    "#     max_depth=10,       # Kept distinct to prevent overfitting\n",
    "#     min_samples_leaf=5, # Added for regularization\n",
    "#     random_state=42,\n",
    "#     replacement=True,\n",
    "#     sampling_strategy='auto',\n",
    "#     n_jobs=-1,          # Use all CPU cores\n",
    "#     verbose=1\n",
    "# )\n",
    "\n",
    "# clf.fit(X_train, y_train)\n",
    "\n",
    "# # =====================================================\n",
    "# # 5. EVALUATION\n",
    "# # =====================================================\n",
    "# print(\"\\n--- Evaluating Model ---\")\n",
    "# y_pred = clf.predict(X_test)\n",
    "# y_prob = clf.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# # 1. Classification Report\n",
    "# print(\"\\nClassification Report:\")\n",
    "# print(classification_report(y_test, y_pred, digits=4))\n",
    "\n",
    "# # 2. ROC AUC\n",
    "# auc = roc_auc_score(y_test, y_prob)\n",
    "# print(f\"ROC AUC Score: {auc:.4f}\")\n",
    "\n",
    "# # 3. Confusion Matrix (Raw counts)\n",
    "# cm = confusion_matrix(y_test, y_pred)\n",
    "# print(\"\\nConfusion Matrix:\")\n",
    "# print(cm)\n",
    "# print(f\"False Positives: {cm[0][1]}\")\n",
    "# print(f\"False Negatives: {cm[1][0]}\")\n",
    "\n",
    "# # =====================================================\n",
    "# # 6. SAVE MODEL\n",
    "# # =====================================================\n",
    "# MODEL_PATH = \"../model/rf_model_imbalanced.pkl\"\n",
    "# joblib.dump(clf, MODEL_PATH)\n",
    "# print(f\"\\nModel saved successfully at: {MODEL_PATH}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f222d002",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data from ../data/processed/bank_transactions_features.csv...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-15 14:32:37,696 - INFO - Split data: X.shape=(200000, 83), y.shape=(200000,)\n",
      "2025-12-15 14:32:37,873 - INFO - Train-test split: X_train=(160000, 83), X_test=(40000, 83)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved feature column list to ../model/columns_used.pkl\n",
      "Scaling features...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-15 14:32:37,957 - INFO - Scaled 5 columns using standard scaler.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved scaler to ../model/scaler.pkl\n",
      "Training BalancedRandomForestClassifier via Helper...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-15 14:32:43,149 - INFO - Trained balanced_random_forest model for classification\n",
      "2025-12-15 14:32:43,291 - INFO - Top 5 feature importances:\n",
      "Transaction_Amount    0.129550\n",
      "Account_Balance       0.102860\n",
      "Age                   0.075354\n",
      "Transaction_Day       0.065404\n",
      "Transaction_Hour      0.063335\n",
      "dtype: float64\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Evaluating Model ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-15 14:32:43,631 - INFO - Evaluation results: {'accuracy': 0.5232, 'precision': 0.048644929070506035, 'recall': 0.4554013875123885, 'f1': 0.08790052606408418, 'roc_auc': np.float64(0.4951332118667238)}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics: {'accuracy': 0.5232, 'precision': 0.048644929070506035, 'recall': 0.4554013875123885, 'f1': 0.08790052606408418, 'roc_auc': np.float64(0.4951332118667238)}\n",
      "\n",
      "Model saved successfully at: ../model/rf_model_imbalanced.pkl\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "import pandas as pd\n",
    "import joblib\n",
    "\n",
    "# Add src to path\n",
    "sys.path.append(\"../src/\")\n",
    "\n",
    "# Import updated helpers\n",
    "from modeling import split_X_y, split_train_test, scale_features, train_simple_model, evaluate_model\n",
    "\n",
    "# =====================================================\n",
    "# 1. SETUP & LOAD\n",
    "# =====================================================\n",
    "os.makedirs(\"../model\", exist_ok=True)\n",
    "FEATURES_PATH = \"../data/processed/bank_transactions_features.csv\"\n",
    "\n",
    "print(f\"Loading data from {FEATURES_PATH}...\")\n",
    "df = pd.read_csv(FEATURES_PATH)\n",
    "\n",
    "# =====================================================\n",
    "# 2. SPLITTING\n",
    "# =====================================================\n",
    "X, y = split_X_y(df, target=\"Is_Fraud\")\n",
    "\n",
    "# --- SAVE METADATA 1: Column Names ---\n",
    "# The Streamlit app needs this to know the order of features\n",
    "cols_path = \"../model/columns_used.pkl\"\n",
    "joblib.dump(X.columns.tolist(), cols_path)\n",
    "print(f\"Saved feature column list to {cols_path}\")\n",
    "\n",
    "# Split Train/Test\n",
    "X_train, X_test, y_train, y_test = split_train_test(X, y, stratify=y)\n",
    "\n",
    "# =====================================================\n",
    "# 3. PREPROCESSING (Scaling)\n",
    "# =====================================================\n",
    "# 1. Handle Missing Values first\n",
    "X_train = X_train.fillna(0)\n",
    "X_test = X_test.fillna(0)\n",
    "\n",
    "# 2. Scale Features & CAPTURE THE SCALER\n",
    "# Even if Trees don't strictly need it, using a scaler allows you \n",
    "# to easily swap to Logistic Regression later without changing the pipeline.\n",
    "print(\"Scaling features...\")\n",
    "scaler, X_train_scaled, X_test_scaled = scale_features(X_train, X_test, method=\"standard\")\n",
    "\n",
    "# --- SAVE METADATA 2: The Scaler ---\n",
    "# CRITICAL: We save the math (mean/std) so the Streamlit app \n",
    "# can transform the user's single input exactly like the training data.\n",
    "if scaler:\n",
    "    scaler_path = \"../model/scaler.pkl\"\n",
    "    joblib.dump(scaler, scaler_path)\n",
    "    print(f\"Saved scaler to {scaler_path}\")\n",
    "\n",
    "# =====================================================\n",
    "# 4. TRAINING\n",
    "# =====================================================\n",
    "print(\"Training BalancedRandomForestClassifier via Helper...\")\n",
    "\n",
    "clf = train_simple_model(\n",
    "    X_train_scaled,  # Use the SCALED data\n",
    "    y_train,\n",
    "    problem=\"classification\",\n",
    "    model_name=\"balanced_random_forest\",\n",
    "    resample=False, # Helper handles this internal logic\n",
    "    # Specific Params\n",
    "    n_estimators=300,\n",
    "    max_depth=10,\n",
    "    min_samples_leaf=5,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# =====================================================\n",
    "# 5. EVALUATION\n",
    "# =====================================================\n",
    "print(\"\\n--- Evaluating Model ---\")\n",
    "metrics = evaluate_model(clf, X_test_scaled, y_test, problem=\"classification\")\n",
    "print(f\"Metrics: {metrics}\")\n",
    "\n",
    "# =====================================================\n",
    "# 6. SAVE MODEL\n",
    "# =====================================================\n",
    "MODEL_PATH = \"../model/rf_model_imbalanced.pkl\"\n",
    "joblib.dump(clf, MODEL_PATH)\n",
    "print(f\"\\nModel saved successfully at: {MODEL_PATH}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
