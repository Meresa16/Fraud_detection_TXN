{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c7fefdb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import sys\n",
    "# sys.path.append(\"../src/\")\n",
    "\n",
    "# import pandas as pd\n",
    "# import joblib\n",
    "# from modeling import split_X_y, split_train_test, scale_features, train_simple_model, evaluate_model\n",
    "# from imblearn.ensemble import BalancedRandomForestClassifier\n",
    "# from sklearn.metrics import classification_report\n",
    "\n",
    "# # --- Load processed CSV (already one-hot encoded) ---\n",
    "# FEATURES_PATH = \"../data/processed/bank_transactions_features.csv\"\n",
    "# df = pd.read_csv(FEATURES_PATH)\n",
    "\n",
    "# # --- Split X / y ---\n",
    "# X = df.drop(columns=[\"Is_Fraud\"])\n",
    "# y = df[\"Is_Fraud\"]\n",
    "\n",
    "# # --- Save column order BEFORE training (for dashboard consistency) ---\n",
    "# columns_used = X.columns.tolist()\n",
    "# joblib.dump(columns_used, \"../model/columns_used.pkl\")\n",
    "\n",
    "# # --- Train/Test split ---\n",
    "# X_train, X_test, y_train, y_test = split_train_test(X, y, stratify=y)\n",
    "\n",
    "# # --- Optional: Scale numeric features ---\n",
    "# X_train_s, X_test_s = scale_features(X_train.fillna(0), X_test.fillna(0))\n",
    "\n",
    "# # --- Train model for imbalanced data ---\n",
    "# clf = BalancedRandomForestClassifier(\n",
    "#     n_estimators=300,\n",
    "#     max_depth=10,\n",
    "#     random_state=42,\n",
    "#     replacement=True  # allows sampling with replacement\n",
    "# )\n",
    "# clf.fit(X_train_s, y_train)\n",
    "\n",
    "# # --- Evaluate ---\n",
    "# y_pred = clf.predict(X_test_s)\n",
    "# print(\"Classification Report:\\n\", classification_report(y_test, y_pred, digits=4))\n",
    "\n",
    "# # ROC AUC for imbalanced data\n",
    "# if hasattr(clf, \"predict_proba\"):\n",
    "#     y_prob = clf.predict_proba(X_test_s)[:, 1]\n",
    "#     from sklearn.metrics import roc_auc_score\n",
    "#     auc = roc_auc_score(y_test, y_prob)\n",
    "#     print(f\"ROC AUC: {auc:.4f}\")\n",
    "\n",
    "# # --- Save trained model ---\n",
    "# MODEL_PATH = \"../model/rf_model_imbalanced.pkl\"\n",
    "# joblib.dump(clf, MODEL_PATH)\n",
    "# print(f\"Balanced Random Forest model saved at: {MODEL_PATH}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f222d002",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import sys\n",
    "# import os\n",
    "# import pandas as pd\n",
    "# import joblib\n",
    "\n",
    "# # Add src to path\n",
    "# sys.path.append(\"../src/\")\n",
    "\n",
    "# # Import updated helpers\n",
    "# from modeling import split_X_y, split_train_test, scale_features, train_simple_model, evaluate_model\n",
    "\n",
    "# # =====================================================\n",
    "# # 1. SETUP & LOAD\n",
    "# # =====================================================\n",
    "# os.makedirs(\"../model\", exist_ok=True)\n",
    "# FEATURES_PATH = \"../data/processed/bank_transactions_features.csv\"\n",
    "\n",
    "# print(f\"Loading data from {FEATURES_PATH}...\")\n",
    "# df = pd.read_csv(FEATURES_PATH)\n",
    "\n",
    "# # =====================================================\n",
    "# # 2. SPLITTING\n",
    "# # =====================================================\n",
    "# X, y = split_X_y(df, target=\"Is_Fraud\")\n",
    "\n",
    "# # --- SAVE METADATA 1: Column Names ---\n",
    "# # The Streamlit app needs this to know the order of features\n",
    "# cols_path = \"../model/columns_used.pkl\"\n",
    "# joblib.dump(X.columns.tolist(), cols_path)\n",
    "# print(f\"Saved feature column list to {cols_path}\")\n",
    "\n",
    "# # Split Train/Test\n",
    "# X_train, X_test, y_train, y_test = split_train_test(X, y, stratify=y)\n",
    "\n",
    "# # =====================================================\n",
    "# # 3. PREPROCESSING (Scaling)\n",
    "# # =====================================================\n",
    "# # 1. Handle Missing Values first\n",
    "# # X_train = X_train.fillna(0)\n",
    "# # X_test = X_test.fillna(0)\n",
    "\n",
    "# # 2. Scale Features & CAPTURE THE SCALER\n",
    "# # Even if Trees don't strictly need it, using a scaler allows you \n",
    "# # to easily swap to Logistic Regression later without changing the pipeline.\n",
    "# print(\"Scaling features...\")\n",
    "# scaler, X_train_scaled, X_test_scaled = scale_features(X_train, X_test, method=\"standard\")\n",
    "\n",
    "# # --- SAVE METADATA 2: The Scaler ---\n",
    "# # CRITICAL: We save the math (mean/std) so the Streamlit app \n",
    "# # can transform the user's single input exactly like the training data.\n",
    "# if scaler:\n",
    "#     scaler_path = \"../model/scaler.pkl\"\n",
    "#     joblib.dump(scaler, scaler_path)\n",
    "#     print(f\"Saved scaler to {scaler_path}\")\n",
    "\n",
    "# # =====================================================\n",
    "# # 4. TRAINING\n",
    "# # =====================================================\n",
    "# print(\"Training BalancedRandomForestClassifier via Helper...\")\n",
    "\n",
    "# clf = train_simple_model(\n",
    "#     X_train_scaled,  # Use the SCALED data\n",
    "#     y_train,\n",
    "#     problem=\"classification\",\n",
    "#     model_name=\"balanced_random_forest\",\n",
    "#     resample=False, # Helper handles this internal logic\n",
    "#     # Specific Params\n",
    "#     n_estimators=300,\n",
    "#     max_depth=10,\n",
    "#     min_samples_leaf=5,\n",
    "#     n_jobs=-1\n",
    "# )\n",
    "\n",
    "# # =====================================================\n",
    "# # 5. EVALUATION\n",
    "# # =====================================================\n",
    "# print(\"\\n--- Evaluating Model ---\")\n",
    "# metrics = evaluate_model(clf, X_test_scaled, y_test, problem=\"classification\")\n",
    "# print(f\"Metrics: {metrics}\")\n",
    "\n",
    "# # =====================================================\n",
    "# # 6. SAVE MODEL\n",
    "# # =====================================================\n",
    "# MODEL_PATH = \"../model/rf_model_imbalanced.pkl\"\n",
    "# joblib.dump(clf, MODEL_PATH)\n",
    "# print(f\"\\nModel saved successfully at: {MODEL_PATH}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e89d50ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data from ../data/processed/bank_transactions_features.csv...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-15 17:22:19,457 - INFO - Split data: X.shape=(200000, 52), y.shape=(200000,)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved feature column list to ../model/columns_used.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-15 17:22:19,690 - INFO - Train-test split: X_train=(160000, 52), X_test=(40000, 52)\n",
      "2025-12-15 17:22:19,848 - INFO - Scaled 6 columns using standard scaler.\n",
      "2025-12-15 17:22:19,920 - INFO - Applying SMOTE to training data...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scaling features...\n",
      "Saved scaler to ../model/scaler.pkl\n",
      "\n",
      "--- Starting Model Competition ---\n",
      "\n",
      "Training logistic...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-15 17:22:25,406 - INFO - SMOTE applied: New X_train=(303860, 52)\n",
      "2025-12-15 17:22:31,235 - INFO - Trained logistic model for classification\n",
      "2025-12-15 17:22:32,286 - INFO - Evaluation results: {'accuracy': 0.94955, 'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'roc_auc': np.float64(0.4956374933011667)}\n",
      "2025-12-15 17:22:32,352 - INFO - Applying SMOTE to training data...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training random_forest...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-15 17:22:32,974 - INFO - SMOTE applied: New X_train=(303860, 52)\n",
      "2025-12-15 17:22:41,901 - INFO - Trained random_forest model for classification\n",
      "2025-12-15 17:22:42,562 - INFO - Top 5 feature importances:\n",
      "Device_Type_Mobile       0.069270\n",
      "Account_Type_Business    0.068810\n",
      "Device_Type_POS          0.068158\n",
      "Device_Type_ATM          0.066329\n",
      "Account_Type_Savings     0.065377\n",
      "dtype: float64\n",
      "2025-12-15 17:22:44,115 - INFO - Evaluation results: {'accuracy': 0.94955, 'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'roc_auc': np.float64(0.4972294267604409)}\n",
      "2025-12-15 17:22:44,139 - INFO - Applying SMOTE to training data...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training gbm...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-15 17:22:46,133 - INFO - SMOTE applied: New X_train=(303860, 52)\n",
      "2025-12-15 17:25:18,276 - INFO - Trained gbm model for classification\n",
      "2025-12-15 17:25:18,665 - INFO - Top 5 feature importances:\n",
      "Device_Type_ATM            0.094176\n",
      "Account_Type_Business      0.091490\n",
      "Device_Type_Desktop        0.086781\n",
      "Transaction_Type_Credit    0.085960\n",
      "Account_Type_Savings       0.077619\n",
      "dtype: float64\n",
      "2025-12-15 17:25:19,528 - INFO - Evaluation results: {'accuracy': 0.949375, 'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'roc_auc': np.float64(0.49894665429908136)}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training balanced_random_forest...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-15 17:25:24,544 - INFO - Trained balanced_random_forest model for classification\n",
      "2025-12-15 17:25:24,696 - INFO - Top 5 feature importances:\n",
      "Transaction_Amount    0.112253\n",
      "Account_Balance       0.100593\n",
      "Customer_Age          0.062968\n",
      "Transaction_Hour      0.062464\n",
      "Age                   0.060242\n",
      "dtype: float64\n",
      "2025-12-15 17:25:25,090 - INFO - Evaluation results: {'accuracy': 0.520775, 'precision': 0.050620971545354505, 'recall': 0.4786917740336967, 'f1': 0.09155964172314109, 'roc_auc': np.float64(0.5005184110213596)}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Model Leaderboard ---\n",
      "               model_name   roc_auc       f1  precision    recall\n",
      "3  balanced_random_forest  0.500518  0.09156   0.050621  0.478692\n",
      "2                     gbm  0.498947  0.00000   0.000000  0.000000\n",
      "1           random_forest  0.497229  0.00000   0.000000  0.000000\n",
      "0                logistic  0.495637  0.00000   0.000000  0.000000\n",
      "\n",
      "üèÜ WINNER: balanced_random_forest\n",
      "   ROC AUC: 0.5005\n",
      "   F1 Score: 0.0916\n",
      "\n",
      "‚úÖ Best model saved successfully at: ../model/rf_model_imbalanced.pkl\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "import pandas as pd\n",
    "import joblib\n",
    "import numpy as np\n",
    "\n",
    "# Add src to path\n",
    "sys.path.append(\"../src/\")\n",
    "\n",
    "# Import helpers\n",
    "from modeling import split_X_y, split_train_test, scale_features, train_simple_model, evaluate_model\n",
    "\n",
    "# =====================================================\n",
    "# 1. SETUP & LOAD\n",
    "# =====================================================\n",
    "os.makedirs(\"../model\", exist_ok=True)\n",
    "FEATURES_PATH = \"../data/processed/bank_transactions_features.csv\"\n",
    "\n",
    "print(f\"Loading data from {FEATURES_PATH}...\")\n",
    "df = pd.read_csv(FEATURES_PATH)\n",
    "\n",
    "# =====================================================\n",
    "# 2. SPLITTING\n",
    "# =====================================================\n",
    "X, y = split_X_y(df, target=\"Is_Fraud\")\n",
    "\n",
    "# --- SAVE METADATA 1: Column Names ---\n",
    "cols_path = \"../model/columns_used.pkl\"\n",
    "joblib.dump(X.columns.tolist(), cols_path)\n",
    "print(f\"Saved feature column list to {cols_path}\")\n",
    "\n",
    "# Split Train/Test\n",
    "X_train, X_test, y_train, y_test = split_train_test(X, y, stratify=y)\n",
    "\n",
    "# =====================================================\n",
    "# 3. PREPROCESSING\n",
    "# =====================================================\n",
    "# 1. Handle Missing Values (Crucial for Logistic Regression)\n",
    "X_train = X_train.fillna(0)\n",
    "X_test = X_test.fillna(0)\n",
    "\n",
    "# 2. Scale Features\n",
    "print(\"Scaling features...\")\n",
    "scaler, X_train_scaled, X_test_scaled = scale_features(X_train, X_test, method=\"standard\")\n",
    "\n",
    "# --- SAVE METADATA 2: The Scaler ---\n",
    "if scaler:\n",
    "    scaler_path = \"../model/scaler.pkl\"\n",
    "    joblib.dump(scaler, scaler_path)\n",
    "    print(f\"Saved scaler to {scaler_path}\")\n",
    "\n",
    "# =====================================================\n",
    "# 4. ITERATIVE TRAINING & SELECTION\n",
    "# =====================================================\n",
    "print(\"\\n--- Starting Model Competition ---\")\n",
    "\n",
    "# Define the candidates\n",
    "# Note: balanced_random_forest handles sampling internally, so resample=False\n",
    "# Others typically benefit from SMOTE (resample=True) in fraud cases\n",
    "model_candidates = [\n",
    "    {\n",
    "        \"name\": \"logistic\", \n",
    "        \"resample\": True, \n",
    "        \"params\": {\"C\": 1.0, \"solver\": \"liblinear\"}\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"random_forest\", \n",
    "        \"resample\": True, \n",
    "        \"params\": {\"n_estimators\": 100, \"max_depth\": 10, \"n_jobs\": -1}\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"gbm\", \n",
    "        \"resample\": True, \n",
    "        \"params\": {\"n_estimators\": 100, \"learning_rate\": 0.1, \"max_depth\": 5}\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"balanced_random_forest\", \n",
    "        \"resample\": False, \n",
    "        \"params\": {\"n_estimators\": 200, \"max_depth\": 10, \"n_jobs\": -1}\n",
    "    }\n",
    "]\n",
    "\n",
    "results = []\n",
    "trained_models = {}\n",
    "\n",
    "for config in model_candidates:\n",
    "    name = config[\"name\"]\n",
    "    print(f\"\\nTraining {name}...\")\n",
    "    \n",
    "    try:\n",
    "        # Train\n",
    "        model = train_simple_model(\n",
    "            X_train_scaled, \n",
    "            y_train,\n",
    "            problem=\"classification\",\n",
    "            model_name=name,\n",
    "            resample=config[\"resample\"],\n",
    "            **config[\"params\"]\n",
    "        )\n",
    "        \n",
    "        # Evaluate\n",
    "        metrics = evaluate_model(model, X_test_scaled, y_test, problem=\"classification\")\n",
    "        \n",
    "        # Store Result\n",
    "        metrics[\"model_name\"] = name\n",
    "        results.append(metrics)\n",
    "        trained_models[name] = model\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Failed to train {name}: {e}\")\n",
    "\n",
    "# =====================================================\n",
    "# 5. SELECT BEST MODEL\n",
    "# =====================================================\n",
    "print(\"\\n--- Model Leaderboard ---\")\n",
    "results_df = pd.DataFrame(results)\n",
    "\n",
    "# Sort by ROC_AUC (Best metric for fraud) or F1\n",
    "# We use ROC_AUC because it measures ranking ability regardless of threshold\n",
    "results_df = results_df.sort_values(by=\"roc_auc\", ascending=False)\n",
    "\n",
    "print(results_df[[\"model_name\", \"roc_auc\", \"f1\", \"precision\", \"recall\"]])\n",
    "\n",
    "# Get the winner\n",
    "best_row = results_df.iloc[0]\n",
    "best_model_name = best_row[\"model_name\"]\n",
    "best_model = trained_models[best_model_name]\n",
    "\n",
    "print(f\"\\nüèÜ WINNER: {best_model_name}\")\n",
    "print(f\"   ROC AUC: {best_row['roc_auc']:.4f}\")\n",
    "print(f\"   F1 Score: {best_row['f1']:.4f}\")\n",
    "\n",
    "# =====================================================\n",
    "# 6. SAVE BEST MODEL\n",
    "# =====================================================\n",
    "# We save it as 'rf_model_imbalanced.pkl' regardless of the type \n",
    "# so the dashboard code doesn't break, OR you can rename it 'best_model.pkl'\n",
    "# and update your dashboard path. Here I keep the name consistent.\n",
    "MODEL_PATH = \"../model/rf_model_imbalanced.pkl\" \n",
    "\n",
    "joblib.dump(best_model, MODEL_PATH)\n",
    "print(f\"\\n‚úÖ Best model saved successfully at: {MODEL_PATH}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
